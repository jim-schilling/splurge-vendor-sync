---
description: testing guidelines and expectations
alwaysApply: false
---
- Follow BDD/TDD (Behavior/Test Driven Development) practices.
- Validate behavior of public APIs only.
- Prefer validation using actual data, interfaces, and objects
- Minimize use of mocks, except where appropriate.
- Mock at architectural boundaries (external systems, I/O) but prefer real objects/data for internal logic.
- Ensure tests are isolated and do not depend on external systems or state.
- Each code module must have at least one corresponding test module.
- Unit test shall target 85% code coverage for all public interfaces and methods.
- Combination of unit tests and integration tests shall target 95% code coverage for all public interfaces and methods.
- Prefer tests that are independent, repeatable, and deterministic.
- Prefer shared helpers for common logic.
- Avoid validation of implementation details and private APIs.
- Prefer validation of patterns of text, and avoid exact matching of content and formatting.
- Prefer pytest; pytest-xdist may be used optionally for parallel runs (e.g., -n 4) when desired.
- Prefer pytest-cov for code coverage with parameters --cov=your_package --cov-report=term-missing.
- Prefer pytest-mock for mocking and patching, where appropriate.
- Run pytest with code coverage when asked by user, otherwise skip.
- Place unit tests in tests/unit/ and integration tests in tests/integration/, e2e tests in tests/e2e/, and performance tests in tests/performance/.
- Place test data in tests/data.
- For Python, prefer pure pytest function style tests.
- For Python, prefer use of tmp_path and tmp_path_factory fixtures for temporary files and directories.
- Name test methods as test_[condition]_[expectedResult].
- Each test method should ideally test a single condition and expected result.
- Use fixtures for common setup and teardown logic.
- Use parameterized tests for testing multiple input scenarios.
- Use assertions to validate expected outcomes.
- Prefer tests/unit/* to run to completion within 60 seconds.
- Prefer tests/integration/* to run to completion within 60 seconds.
- Prefer tests/e2e/* to run to run to completion within 60 seconds.
- Prefer tests/performance/* to run to completion within 60 seconds.
- Prefer entire test suite to run to completion within 120 seconds.
